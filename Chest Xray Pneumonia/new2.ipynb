{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"name":"python","version":"3.11.13","mimetype":"text/x-python","codemirror_mode":{"name":"ipython","version":3},"pygments_lexer":"ipython3","nbconvert_exporter":"python","file_extension":".py"},"kaggle":{"accelerator":"nvidiaTeslaT4","dataSources":[{"sourceId":23812,"sourceType":"datasetVersion","datasetId":17810}],"dockerImageVersionId":31090,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"markdown","source":"<h2>Changes:</h2>\n<ol>\n    <li>max_lr changed to 0.005 in scheduler</li>\n    <li>Dropout increased to 0.5</li>\n    <li>Added clipping gradients by norm</li>\n</ol>","metadata":{}},{"cell_type":"code","source":"import torch\nimport torch.nn as nn\nimport torch.optim\nimport torchvision\nfrom torchvision import datasets, transforms\nimport torchvision.models as models\nfrom torchvision.models import resnet18, ResNet18_Weights\nfrom torch.utils.data import DataLoader, random_split, Subset, WeightedRandomSampler\n\nfrom sklearn.model_selection import StratifiedKFold\n\nfrom torchmetrics.classification import Accuracy","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true,"execution":{"iopub.status.busy":"2025-09-07T11:52:34.088718Z","iopub.execute_input":"2025-09-07T11:52:34.088987Z","iopub.status.idle":"2025-09-07T11:52:45.973764Z","shell.execute_reply.started":"2025-09-07T11:52:34.088964Z","shell.execute_reply":"2025-09-07T11:52:45.973166Z"}},"outputs":[],"execution_count":1},{"cell_type":"code","source":"device= torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\ndevice","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T11:52:45.974835Z","iopub.execute_input":"2025-09-07T11:52:45.975190Z","iopub.status.idle":"2025-09-07T11:52:46.056289Z","shell.execute_reply.started":"2025-09-07T11:52:45.975171Z","shell.execute_reply":"2025-09-07T11:52:46.055532Z"}},"outputs":[{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"device(type='cuda')"},"metadata":{}}],"execution_count":2},{"cell_type":"code","source":"train_transform= transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.RandomHorizontalFlip(),\n    transforms.RandomRotation(10),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\nval_transform= transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])\n\ntest_transform= transforms.Compose([\n    transforms.Resize((224,224)),\n    transforms.ToTensor(),\n    transforms.Normalize(mean=[0.485, 0.456, 0.406],\n                         std=[0.229, 0.224, 0.225])\n])","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T11:52:46.057356Z","iopub.execute_input":"2025-09-07T11:52:46.058420Z","iopub.status.idle":"2025-09-07T11:52:46.078102Z","shell.execute_reply.started":"2025-09-07T11:52:46.058390Z","shell.execute_reply":"2025-09-07T11:52:46.077487Z"}},"outputs":[],"execution_count":3},{"cell_type":"code","source":"full_train_dir= \"/kaggle/input/chest-xray-pneumonia/chest_xray/train\"\nfull_train= datasets.ImageFolder(root=full_train_dir, transform= train_transform)\nfull_train_val= datasets.ImageFolder(root=full_train_dir, transform= val_transform)\n\n# full_train.samples returns (image, label) so s[1] imples fetching the labels\nlabels = [s[1] for s in full_train.samples]\n\ntest_dir= \"/kaggle/input/chest-xray-pneumonia/chest_xray/test\"\ntest_set= datasets.ImageFolder(root=test_dir, transform= test_transform)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T11:52:46.079829Z","iopub.execute_input":"2025-09-07T11:52:46.080009Z","iopub.status.idle":"2025-09-07T11:52:50.579846Z","shell.execute_reply.started":"2025-09-07T11:52:46.079994Z","shell.execute_reply":"2025-09-07T11:52:50.579255Z"}},"outputs":[],"execution_count":4},{"cell_type":"code","source":"# Treating class imbalance\nclass_counts= torch.tensor([labels.count(0), labels.count(1)], dtype= torch.float)\nclass_weights= 1./class_counts\nsample_weights= class_weights[[label for _, label in full_train.samples]]\n\n\nprint(class_counts, class_weights, sample_weights)\n\n# Dataset is imbalanced in 1:3 ratio","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T11:52:50.580468Z","iopub.execute_input":"2025-09-07T11:52:50.580676Z","iopub.status.idle":"2025-09-07T11:52:50.616627Z","shell.execute_reply.started":"2025-09-07T11:52:50.580658Z","shell.execute_reply":"2025-09-07T11:52:50.615933Z"}},"outputs":[{"name":"stdout","text":"tensor([1341., 3875.]) tensor([0.0007, 0.0003]) tensor([0.0007, 0.0007, 0.0007,  ..., 0.0003, 0.0003, 0.0003])\n","output_type":"stream"}],"execution_count":5},{"cell_type":"code","source":"model= models.resnet18(weights=ResNet18_Weights.DEFAULT)\nmodel.fc= nn.Sequential(\n    nn.Linear(model.fc.in_features, 512),\n    nn.ReLU(),\n    nn.Dropout(0.5),\n    nn.Linear(512,2)\n)\nmodel=model.to(device)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T11:52:50.617333Z","iopub.execute_input":"2025-09-07T11:52:50.617705Z","iopub.status.idle":"2025-09-07T11:52:51.458449Z","shell.execute_reply.started":"2025-09-07T11:52:50.617669Z","shell.execute_reply":"2025-09-07T11:52:51.457869Z"}},"outputs":[{"name":"stderr","text":"Downloading: \"https://download.pytorch.org/models/resnet18-f37072fd.pth\" to /root/.cache/torch/hub/checkpoints/resnet18-f37072fd.pth\n100%|██████████| 44.7M/44.7M [00:00<00:00, 180MB/s] \n","output_type":"stream"}],"execution_count":6},{"cell_type":"code","source":"def train(dataloader, model, loss_function, optimizer):\n    model.train()\n    total_loss=0\n\n    for batch, (image, label) in enumerate(dataloader):\n        image, label= image.to(device), label.to(device)\n        prediction= model(image)\n        loss= loss_function(prediction, label)\n        loss.backward()\n\n        #Gradient clipping to mitigate the exploding gradients\n        torch.nn.utils.clip_grad_norm_(model.parameters(), max_norm=1.0)\n\n        optimizer.step()\n        scheduler.step()\n        optimizer.zero_grad()\n\n        total_loss+= loss\n    avg_loss= total_loss/len(dataloader)\n    print(f\"Training Average Loss: {avg_loss:.4f}\")\n\n    \n        ","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T11:52:51.459241Z","iopub.execute_input":"2025-09-07T11:52:51.459499Z","iopub.status.idle":"2025-09-07T11:52:51.464808Z","shell.execute_reply.started":"2025-09-07T11:52:51.459481Z","shell.execute_reply":"2025-09-07T11:52:51.463942Z"}},"outputs":[],"execution_count":7},{"cell_type":"code","source":"val_accuracy= Accuracy(task=\"multiclass\", num_classes=2).to(device)\n\ndef validate(dataloader, model, loss_function):\n    model.eval()\n    total_loss=0\n    val_accuracy.reset()\n\n    with torch.no_grad():\n        for image, label in dataloader:\n            image, label= image.to(device), label.to(device)\n            prediction= model(image)\n            loss= loss_function(prediction, label)\n            total_loss+= loss\n\n            val_accuracy.update(prediction, label)\n            \n        avg_loss= total_loss/ len(dataloader)\n        accuracy= val_accuracy.compute()*100\n        print(f\"Validation Loss: {avg_loss:.4f}\")\n        print(f\"Validation Accuracy: {accuracy:.2f}\")\n\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T11:52:51.465584Z","iopub.execute_input":"2025-09-07T11:52:51.465935Z","iopub.status.idle":"2025-09-07T11:52:51.498201Z","shell.execute_reply.started":"2025-09-07T11:52:51.465911Z","shell.execute_reply":"2025-09-07T11:52:51.497458Z"}},"outputs":[],"execution_count":8},{"cell_type":"code","source":"test_accuracy= Accuracy(task=\"multiclass\", num_classes=2).to(device)\n\ndef test(dataloader, model, loss_function):\n    model.eval()\n    total_loss=0\n    val_accuracy.reset()\n\n    with torch.no_grad():\n        for image, label in dataloader:\n            image= image.to(device)  # shape: (batch_size, C, H, W)\n            label= label.to(device)  # shape: (batch_size,)\n            prediction= model(image)\n            loss= loss_function(prediction, label)\n            total_loss+= loss\n\n            test_accuracy.update(prediction, label)\n\n        avg_loss= total_loss/ len(dataloader)\n        accuracy= test_accuracy.compute()*100\n    print(f\"Test Loss: {avg_loss:.4f}\")\n    print(f\"Test Accuracy: {accuracy:.2f}\")\n\n    return accuracy","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T11:52:51.498932Z","iopub.execute_input":"2025-09-07T11:52:51.499705Z","iopub.status.idle":"2025-09-07T11:52:51.505958Z","shell.execute_reply.started":"2025-09-07T11:52:51.499678Z","shell.execute_reply":"2025-09-07T11:52:51.505406Z"}},"outputs":[],"execution_count":9},{"cell_type":"code","source":"epochs=20\n\nskf= StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\nfor fold, (train_idx, val_idx) in enumerate(skf.split(full_train.samples, labels)):\n    print(f\"\\n--------------Fold {fold+1}------------\")\n    print(f\"Train size: {len(train_idx)}, Val size: {len(val_idx)}\")\n\n    train_subset= Subset(full_train, train_idx)\n    val_subset= Subset(full_train_val, val_idx)\n\n    #Creating train sampler\n    train_sampler= WeightedRandomSampler(\n        weights=sample_weights[train_idx],\n        num_samples=len(train_idx),\n        replacement=True\n    )\n\n    \n    train_loader= DataLoader(train_subset, sampler= train_sampler, batch_size=64, shuffle=False, num_workers=2) # shuffle has to be false!!\n    val_loader= DataLoader(val_subset, batch_size=64, shuffle=False, num_workers=2)\n\n\n    model= models.resnet18(weights=ResNet18_Weights.DEFAULT)\n    model.fc= nn.Sequential(\n        nn.Linear(model.fc.in_features, 512),\n        nn.ReLU(),\n        nn.Dropout(0.4),\n        nn.Linear(512,2)\n    )\n    model=model.to(device)\n    \n    loss_function= nn.CrossEntropyLoss()\n    optimizer= torch.optim.Adam(model.parameters(), lr=0.001, weight_decay=1e-4)\n    scheduler= torch.optim.lr_scheduler.OneCycleLR(optimizer, max_lr=0.005, steps_per_epoch= len(train_loader), epochs= epochs)\n\n    best_val_acc= 0.0\n\n    for epoch in range(epochs):\n        print(f\"Epoch {epoch+1}/{epochs}\")\n        train(train_loader, model, loss_function, optimizer)\n        val_acc= validate(val_loader, model, loss_function)\n\n        if val_acc > best_val_acc:\n            best_val_acc= val_acc\n    print(f\"Best Validation Accuracy in Fold {fold+1}: {best_val_acc:.2f}%\")\n    print(f\"-----------------------------------------------------------------\")\n\n\nprint(\"\\n\")\ntest_loader= DataLoader(test_set, batch_size=64, shuffle=False, num_workers=2)\ntest(test_loader, model, loss_function)","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-09-07T11:52:51.507824Z","iopub.execute_input":"2025-09-07T11:52:51.508018Z","iopub.status.idle":"2025-09-07T13:28:08.860742Z","shell.execute_reply.started":"2025-09-07T11:52:51.508003Z","shell.execute_reply":"2025-09-07T13:28:08.859488Z"}},"outputs":[{"name":"stdout","text":"\n--------------Fold 1------------\nTrain size: 4172, Val size: 1044\nEpoch 1/20\nTraining Average Loss: 0.1263\nValidation Loss: 1.2746\nValidation Accuracy: 71.84\nEpoch 2/20\nTraining Average Loss: 0.0912\nValidation Loss: 0.1905\nValidation Accuracy: 93.68\nEpoch 3/20\nTraining Average Loss: 0.1239\nValidation Loss: 0.0975\nValidation Accuracy: 96.55\nEpoch 4/20\nTraining Average Loss: 0.1558\nValidation Loss: 0.9466\nValidation Accuracy: 56.42\nEpoch 5/20\nTraining Average Loss: 0.1423\nValidation Loss: 0.7600\nValidation Accuracy: 72.51\nEpoch 6/20\nTraining Average Loss: 0.1474\nValidation Loss: 0.1381\nValidation Accuracy: 94.16\nEpoch 7/20\nTraining Average Loss: 0.1087\nValidation Loss: 0.4293\nValidation Accuracy: 93.20\nEpoch 8/20\nTraining Average Loss: 0.1096\nValidation Loss: 0.0545\nValidation Accuracy: 97.41\nEpoch 9/20\nTraining Average Loss: 0.0835\nValidation Loss: 0.0862\nValidation Accuracy: 97.03\nEpoch 10/20\nTraining Average Loss: 0.0805\nValidation Loss: 0.0661\nValidation Accuracy: 97.80\nEpoch 11/20\nTraining Average Loss: 0.0769\nValidation Loss: 0.1070\nValidation Accuracy: 95.21\nEpoch 12/20\nTraining Average Loss: 0.0712\nValidation Loss: 0.1628\nValidation Accuracy: 95.59\nEpoch 13/20\nTraining Average Loss: 0.0710\nValidation Loss: 0.0803\nValidation Accuracy: 96.65\nEpoch 14/20\nTraining Average Loss: 0.0633\nValidation Loss: 0.0506\nValidation Accuracy: 97.80\nEpoch 15/20\nTraining Average Loss: 0.0381\nValidation Loss: 0.0570\nValidation Accuracy: 97.80\nEpoch 16/20\nTraining Average Loss: 0.0477\nValidation Loss: 0.0495\nValidation Accuracy: 97.51\nEpoch 17/20\nTraining Average Loss: 0.0374\nValidation Loss: 0.0432\nValidation Accuracy: 98.18\nEpoch 18/20\nTraining Average Loss: 0.0293\nValidation Loss: 0.0499\nValidation Accuracy: 98.56\nEpoch 19/20\nTraining Average Loss: 0.0201\nValidation Loss: 0.0513\nValidation Accuracy: 97.99\nEpoch 20/20\nTraining Average Loss: 0.0185\nValidation Loss: 0.0507\nValidation Accuracy: 98.18\nBest Validation Accuracy in Fold 1: 98.56%\n-----------------------------------------------------------------\n\n--------------Fold 2------------\nTrain size: 4173, Val size: 1043\nEpoch 1/20\nTraining Average Loss: 0.1237\nValidation Loss: 0.1218\nValidation Accuracy: 95.21\nEpoch 2/20\nTraining Average Loss: 0.1029\nValidation Loss: 0.3455\nValidation Accuracy: 92.23\nEpoch 3/20\nTraining Average Loss: 0.1184\nValidation Loss: 0.2030\nValidation Accuracy: 93.86\nEpoch 4/20\nTraining Average Loss: 0.1320\nValidation Loss: 0.6233\nValidation Accuracy: 82.07\nEpoch 5/20\nTraining Average Loss: 0.1510\nValidation Loss: 0.3390\nValidation Accuracy: 88.21\nEpoch 6/20\nTraining Average Loss: 0.1496\nValidation Loss: 0.0841\nValidation Accuracy: 96.26\nEpoch 7/20\nTraining Average Loss: 0.1130\nValidation Loss: 0.4387\nValidation Accuracy: 89.36\nEpoch 8/20\nTraining Average Loss: 0.1245\nValidation Loss: 0.0896\nValidation Accuracy: 97.03\nEpoch 9/20\nTraining Average Loss: 0.0935\nValidation Loss: 0.1435\nValidation Accuracy: 95.69\nEpoch 10/20\nTraining Average Loss: 0.0787\nValidation Loss: 0.0472\nValidation Accuracy: 98.56\nEpoch 11/20\nTraining Average Loss: 0.0856\nValidation Loss: 0.0885\nValidation Accuracy: 97.03\nEpoch 12/20\nTraining Average Loss: 0.0745\nValidation Loss: 0.6104\nValidation Accuracy: 82.65\nEpoch 13/20\nTraining Average Loss: 0.0623\nValidation Loss: 0.0447\nValidation Accuracy: 98.08\nEpoch 14/20\nTraining Average Loss: 0.0598\nValidation Loss: 0.0911\nValidation Accuracy: 96.55\nEpoch 15/20\nTraining Average Loss: 0.0498\nValidation Loss: 0.0474\nValidation Accuracy: 98.27\nEpoch 16/20\nTraining Average Loss: 0.0373\nValidation Loss: 0.0669\nValidation Accuracy: 97.12\nEpoch 17/20\nTraining Average Loss: 0.0373\nValidation Loss: 0.0626\nValidation Accuracy: 97.79\nEpoch 18/20\nTraining Average Loss: 0.0283\nValidation Loss: 0.0372\nValidation Accuracy: 98.56\nEpoch 19/20\nTraining Average Loss: 0.0237\nValidation Loss: 0.0495\nValidation Accuracy: 98.37\nEpoch 20/20\nTraining Average Loss: 0.0242\nValidation Loss: 0.0510\nValidation Accuracy: 98.37\nBest Validation Accuracy in Fold 2: 98.56%\n-----------------------------------------------------------------\n\n--------------Fold 3------------\nTrain size: 4173, Val size: 1043\nEpoch 1/20\nTraining Average Loss: 0.1250\nValidation Loss: 0.1660\nValidation Accuracy: 94.63\nEpoch 2/20\nTraining Average Loss: 0.0906\nValidation Loss: 2.9816\nValidation Accuracy: 58.58\nEpoch 3/20\nTraining Average Loss: 0.1181\nValidation Loss: 8.4744\nValidation Accuracy: 28.28\nEpoch 4/20\nTraining Average Loss: 0.1356\nValidation Loss: 0.1320\nValidation Accuracy: 94.92\nEpoch 5/20\nTraining Average Loss: 0.1467\nValidation Loss: 0.3156\nValidation Accuracy: 94.06\nEpoch 6/20\nTraining Average Loss: 0.1380\nValidation Loss: 0.1265\nValidation Accuracy: 95.69\nEpoch 7/20\nTraining Average Loss: 0.1050\nValidation Loss: 0.2887\nValidation Accuracy: 92.23\nEpoch 8/20\nTraining Average Loss: 0.1038\nValidation Loss: 1.2315\nValidation Accuracy: 82.65\nEpoch 9/20\nTraining Average Loss: 0.1056\nValidation Loss: 0.0907\nValidation Accuracy: 97.22\nEpoch 10/20\nTraining Average Loss: 0.0857\nValidation Loss: 0.1268\nValidation Accuracy: 95.69\nEpoch 11/20\nTraining Average Loss: 0.0715\nValidation Loss: 0.2228\nValidation Accuracy: 92.71\nEpoch 12/20\nTraining Average Loss: 0.0673\nValidation Loss: 0.1095\nValidation Accuracy: 95.97\nEpoch 13/20\nTraining Average Loss: 0.0551\nValidation Loss: 0.0629\nValidation Accuracy: 98.27\nEpoch 14/20\nTraining Average Loss: 0.0507\nValidation Loss: 0.1523\nValidation Accuracy: 94.73\nEpoch 15/20\nTraining Average Loss: 0.0422\nValidation Loss: 0.1001\nValidation Accuracy: 96.84\nEpoch 16/20\nTraining Average Loss: 0.0345\nValidation Loss: 0.0662\nValidation Accuracy: 97.70\nEpoch 17/20\nTraining Average Loss: 0.0404\nValidation Loss: 0.0676\nValidation Accuracy: 97.79\nEpoch 18/20\nTraining Average Loss: 0.0236\nValidation Loss: 0.0576\nValidation Accuracy: 98.08\nEpoch 19/20\nTraining Average Loss: 0.0223\nValidation Loss: 0.0555\nValidation Accuracy: 98.08\nEpoch 20/20\nTraining Average Loss: 0.0175\nValidation Loss: 0.0577\nValidation Accuracy: 98.18\nBest Validation Accuracy in Fold 3: 98.27%\n-----------------------------------------------------------------\n\n--------------Fold 4------------\nTrain size: 4173, Val size: 1043\nEpoch 1/20\nTraining Average Loss: 0.1144\nValidation Loss: 0.1781\nValidation Accuracy: 94.15\nEpoch 2/20\nTraining Average Loss: 0.1047\nValidation Loss: 0.3768\nValidation Accuracy: 88.02\nEpoch 3/20\nTraining Average Loss: 0.1241\nValidation Loss: 1.1803\nValidation Accuracy: 79.29\nEpoch 4/20\nTraining Average Loss: 0.1511\nValidation Loss: 0.3289\nValidation Accuracy: 89.74\nEpoch 5/20\nTraining Average Loss: 0.1352\nValidation Loss: 0.1564\nValidation Accuracy: 95.78\nEpoch 6/20\nTraining Average Loss: 0.1236\nValidation Loss: 0.1709\nValidation Accuracy: 94.44\nEpoch 7/20\nTraining Average Loss: 0.1112\nValidation Loss: 0.0719\nValidation Accuracy: 97.32\nEpoch 8/20\nTraining Average Loss: 0.1025\nValidation Loss: 0.8117\nValidation Accuracy: 82.74\nEpoch 9/20\nTraining Average Loss: 0.1083\nValidation Loss: 0.0730\nValidation Accuracy: 97.51\nEpoch 10/20\nTraining Average Loss: 0.0790\nValidation Loss: 0.1679\nValidation Accuracy: 94.15\nEpoch 11/20\nTraining Average Loss: 0.0780\nValidation Loss: 0.0642\nValidation Accuracy: 97.32\nEpoch 12/20\nTraining Average Loss: 0.0604\nValidation Loss: 0.0600\nValidation Accuracy: 97.70\nEpoch 13/20\nTraining Average Loss: 0.0586\nValidation Loss: 0.0436\nValidation Accuracy: 98.18\nEpoch 14/20\nTraining Average Loss: 0.0593\nValidation Loss: 0.0526\nValidation Accuracy: 98.27\nEpoch 15/20\nTraining Average Loss: 0.0495\nValidation Loss: 0.0720\nValidation Accuracy: 97.41\nEpoch 16/20\nTraining Average Loss: 0.0371\nValidation Loss: 0.0371\nValidation Accuracy: 98.66\nEpoch 17/20\nTraining Average Loss: 0.0356\nValidation Loss: 0.0296\nValidation Accuracy: 98.85\nEpoch 18/20\nTraining Average Loss: 0.0292\nValidation Loss: 0.0416\nValidation Accuracy: 98.08\nEpoch 19/20\nTraining Average Loss: 0.0271\nValidation Loss: 0.0452\nValidation Accuracy: 98.18\nEpoch 20/20\nTraining Average Loss: 0.0257\nValidation Loss: 0.0400\nValidation Accuracy: 98.47\nBest Validation Accuracy in Fold 4: 98.85%\n-----------------------------------------------------------------\n\n--------------Fold 5------------\nTrain size: 4173, Val size: 1043\nEpoch 1/20\nTraining Average Loss: 0.1334\nValidation Loss: 0.0696\nValidation Accuracy: 97.22\nEpoch 2/20\nTraining Average Loss: 0.0913\nValidation Loss: 0.1682\nValidation Accuracy: 95.11\nEpoch 3/20\nTraining Average Loss: 0.1320\nValidation Loss: 1.6856\nValidation Accuracy: 40.27\nEpoch 4/20\nTraining Average Loss: 0.1208\nValidation Loss: 0.1461\nValidation Accuracy: 94.34\nEpoch 5/20\nTraining Average Loss: 0.1530\nValidation Loss: 0.7608\nValidation Accuracy: 80.44\nEpoch 6/20\nTraining Average Loss: 0.1540\nValidation Loss: 0.2645\nValidation Accuracy: 90.03\nEpoch 7/20\nTraining Average Loss: 0.1097\nValidation Loss: 0.0635\nValidation Accuracy: 97.22\nEpoch 8/20\nTraining Average Loss: 0.0986\nValidation Loss: 0.2407\nValidation Accuracy: 92.23\nEpoch 9/20\nTraining Average Loss: 0.1060\nValidation Loss: 0.1444\nValidation Accuracy: 94.34\nEpoch 10/20\nTraining Average Loss: 0.0831\nValidation Loss: 0.1280\nValidation Accuracy: 95.11\nEpoch 11/20\nTraining Average Loss: 0.0701\nValidation Loss: 0.0906\nValidation Accuracy: 97.22\nEpoch 12/20\nTraining Average Loss: 0.0734\nValidation Loss: 0.0576\nValidation Accuracy: 97.12\nEpoch 13/20\nTraining Average Loss: 0.0681\nValidation Loss: 0.1107\nValidation Accuracy: 96.16\nEpoch 14/20\nTraining Average Loss: 0.0593\nValidation Loss: 0.2151\nValidation Accuracy: 93.10\nEpoch 15/20\nTraining Average Loss: 0.0484\nValidation Loss: 0.0573\nValidation Accuracy: 97.70\nEpoch 16/20\nTraining Average Loss: 0.0437\nValidation Loss: 0.0562\nValidation Accuracy: 97.79\nEpoch 17/20\nTraining Average Loss: 0.0325\nValidation Loss: 0.0467\nValidation Accuracy: 98.08\nEpoch 18/20\nTraining Average Loss: 0.0266\nValidation Loss: 0.0459\nValidation Accuracy: 98.56\nEpoch 19/20\nTraining Average Loss: 0.0176\nValidation Loss: 0.0452\nValidation Accuracy: 98.27\nEpoch 20/20\nTraining Average Loss: 0.0166\nValidation Loss: 0.0470\nValidation Accuracy: 98.18\nBest Validation Accuracy in Fold 5: 98.56%\n-----------------------------------------------------------------\n\n\nTest Loss: 0.8117\nTest Accuracy: 84.94\n","output_type":"stream"},{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"tensor(84.9359, device='cuda:0')"},"metadata":{}}],"execution_count":10}]}